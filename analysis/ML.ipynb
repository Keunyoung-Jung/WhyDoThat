{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "abstract-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from konlpy.tag import Okt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from random import sample\n",
    "\n",
    "converter = Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "invisible-profession",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('컴퓨터', 'Noun'),\n",
       " ('개발자', 'Noun'),\n",
       " ('구인', 'Noun'),\n",
       " ('합니다', 'Verb'),\n",
       " ('.', 'Punctuation')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converter.pos(\"컴퓨터 개발자 구인합니다.\".replace('비전','비젼'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "communist-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_df = pd.read_csv('total_df.csv')\n",
    "shuffle_df1 = total_df.sample(frac=1).reset_index(drop=True)\n",
    "shuffle_df2 = total_df.sample(frac=1).reset_index(drop=True)\n",
    "shuffle_df3 = total_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "title = total_df['title']\n",
    "labels = pd.read_csv('label.csv')\n",
    "\n",
    "sector_dict = dict(zip(list(labels['label']),list(labels['index'])))\n",
    "\n",
    "sector_label = list(total_df['sector'])\n",
    "shuffle1_label = list(shuffle_df1['sector'])\n",
    "shuffle2_label = list(shuffle_df2['sector'])\n",
    "shuffle3_label = list(shuffle_df3['sector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lesbian-bristol",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [00:04, 786.36it/s] \n",
      "3481it [00:01, 2369.75it/s]\n",
      "3481it [00:01, 2355.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['NODE JS BACKEND 개발자',\n",
       " '단비 NODE JS REACT TYPESCRIPT 개발자',\n",
       " 'JAVA 개발 비즈니스 플랫폼',\n",
       " 'COUPANG PAY PRINCIPAL TECHNICAL PROGRAM MANAGEMENT',\n",
       " '핀 테크 파운트 FULL STACK ENGINEER',\n",
       " '핀 테크 파운트 프론트엔드 개발자',\n",
       " '백엔드 서비스 개발',\n",
       " '다짐 백엔드 개발자 이상',\n",
       " 'PHP MYSQL JAVA 정규 경력 개발자 모집',\n",
       " '프론트엔드 개발자 신입 채용',\n",
       " '크립 토네이도 서버 개발자',\n",
       " '블록 체인 서비스 백엔드 개발자',\n",
       " '더 리움 클레이튼 기반 플랫폼 개발자',\n",
       " '어드민 풀 스택 개발자',\n",
       " 'QA 담당자',\n",
       " '코리아 웹개발자 앱 개발자 경력 채용',\n",
       " '인슈 테크 스타트업 주 웰그램 개발자',\n",
       " '프리 윌린 프론트엔드 개발자 주니어',\n",
       " 'QA QA ENGINEER 매 플랫',\n",
       " '프리 윌린 프론트엔드 개발자 시니어',\n",
       " '개발 IOS 개발자 B C',\n",
       " '프리 윌린 백엔드 개발자 시니어',\n",
       " 'QA 엔지니어',\n",
       " 'IOS 개발자',\n",
       " 'BACKEND DEVELOPER',\n",
       " 'FRONTEND ENGINEER',\n",
       " '사업 TYPESCRIPT BACKEND 엔지니어',\n",
       " 'FRONT END DEVELOPER ANGULAR',\n",
       " '개발 팀 시니어 FULL STACK 개발자 정규직 경력 모집',\n",
       " '개발 팀 시니어 FRONT END 개발자 정규직 경력 모집',\n",
       " '개발 팀 사내 프로젝트 서버 개발 정규직 경력 모집',\n",
       " '프론트엔드 엔지니어 시니어',\n",
       " '데이터 엔지니어',\n",
       " '백엔드 엔지니어 시니어',\n",
       " 'IOS 엔지니어',\n",
       " '안드로이드 엔지니어',\n",
       " '임 포트 개발 기획 동료 지원',\n",
       " '차이 카드 페이 QA ENGINEER',\n",
       " '차이 카드 페이 DEVOPS ENGINEER',\n",
       " '임 포트 SENIOR FRONT END ENGINEER',\n",
       " '임 포트 BACK END ENGINEER',\n",
       " '임 포트 IOS ENGINEER IOS 모바일 SDK 구축',\n",
       " '차이 카드 페이 QA ENGINEER',\n",
       " '신입 경력 안드로이드 IOS 앱 개발 내일 지원',\n",
       " '웹 개발자 HTML JAVA API 개발 백엔드 개발자',\n",
       " '산업 용 IOT 백엔드 서버 개발자',\n",
       " '모바일 앱 개발자 경력 모집',\n",
       " '주 티 헬 스케 FRONTND 개발자 SW 개발 팀 채용',\n",
       " '서비스 및 UI UX 기획 경력 직 채용 SW 개발 팀 주 티 헬 스케',\n",
       " '글로벌 B C 앱 자신감 모바일 개발 시니어',\n",
       " '슈가힐 네모 서버 개발자 SERVER DEVELOPER',\n",
       " '데이터 엔지니어',\n",
       " '백엔드 서버 개발자',\n",
       " '웹개발자 경력 모집 PHP JAVASCRIPT',\n",
       " '드랍 REACT REACTNATIVE 개발',\n",
       " '풀 스택 엔지니어 경력 이상',\n",
       " '국민 피티 IOS 앱 개발자',\n",
       " '인공 지능 AI 개발 딥 러닝 머신 러닝 등 AI 개발 경력',\n",
       " 'FRONT END 엔지니어',\n",
       " '파이썬 백엔드 개발자',\n",
       " 'IT COMPLIANCE ENGINEER',\n",
       " 'DATA ENGINEER',\n",
       " '광고 플랫폼 개발 전문가',\n",
       " 'GMP GOOGLE MARKETING PLATFORM 구글 마케팅 플랫폼 엔지니어',\n",
       " '데이터 티스 트 전문가',\n",
       " 'ANDROID 엔지니어 KOTLIN RXKOTLIN MVVM',\n",
       " 'BACK END 엔지니어',\n",
       " '머신 러닝 리 처 시니어 주니어',\n",
       " '프론트엔드 엔지니어 경력 이상',\n",
       " '프론트엔드 엔지니어 신입',\n",
       " '테크 리드',\n",
       " 'VP OF ENGINEERING',\n",
       " '소프트웨어 엔지니어 인턴 전환',\n",
       " '풀 스택 엔지니어 경력 이상',\n",
       " '프론트엔드 엔지니어 경력 이상',\n",
       " '판다 코퍼레이션 웹 FRONT END 개발 경력 직 채용',\n",
       " '서비스 및 플랫폼 개발자',\n",
       " 'BACK END 개발자 구합 니',\n",
       " 'FLUTTER 개발자',\n",
       " '지구 구 영웅 위 풀 스택 웹 개발자 구합 니',\n",
       " '자전거 스타트업 백엔드 프론트엔드 개발자 팀 모집',\n",
       " 'BACK END ENGINEER',\n",
       " '울산 지사 인공 지능 빅데이터 연구개발 기술 총괄 본부장',\n",
       " '보안 운영 담당자 모집',\n",
       " '대표이사 엉덩이 앤드 개발자',\n",
       " '커머스 WEB FRONTEND DEVELOPER',\n",
       " 'IOS 개발 자신 프론트 앤드 개발자',\n",
       " '백엔드 프로그래머',\n",
       " 'IOS 프로그래머',\n",
       " '프론트엔드 프로그래머',\n",
       " '안드로이드 프로그래머',\n",
       " '백엔드 개발자',\n",
       " '금융 웹 개발자 프리랜서 모집',\n",
       " '교육 플랫폼 FRONTEND BACKEND 엔지니어',\n",
       " 'FRONT END 개발자',\n",
       " 'BACK END 개발자',\n",
       " 'S W 개발',\n",
       " '데이터 티스 트',\n",
       " '백엔드 개발자',\n",
       " '영상 기반 인공 지능 AI 피트니스 앱 개발자 경력 직 명 채용',\n",
       " 'API WEB 개발자 BACK END SENIOR',\n",
       " 'API WEB 개발자 BACK END JUNIOR',\n",
       " '상상 텃밭 스마트 개발자 모집 경력',\n",
       " '상상 텃밭 스마트 개발자 모집 신입',\n",
       " 'REACT NATIVE 소프트웨어 엔지니어',\n",
       " 'FRONTEND SOFTWARE ENGINEER AI TRIBE',\n",
       " 'JUNIOR BACKEND SOFTWARE ENGINEER 백엔드 개발자',\n",
       " '프론트엔드 VUE JS 개발자',\n",
       " '로보틱스 개발자 ROBOTICS ENGINEER',\n",
       " 'FRONTEND BACKEND 개발자',\n",
       " '인프라 자동화 백엔드',\n",
       " '게임 개발 QA 전문가',\n",
       " 'QA 업무 시스템 기획',\n",
       " 'SENIOR QA ENGINEER COUPANG EATS',\n",
       " 'CLOUD MANAGEMENT SERVICE 개발자',\n",
       " 'FRONTEND SOFTWARE ENGINEER AI TRIBE',\n",
       " 'PRINCIPAL IOS ENGINEER COUPANG EATS',\n",
       " 'PRINCIPAL ANDROID ENGINEER COUPANG EATS',\n",
       " 'SENIOR BACKEND SOFTWARE ENGINEER 백엔드 개발자',\n",
       " 'JUNIOR FRONTEND SOFTWARE ENGINEER 프론트엔드 개발자',\n",
       " 'SENIOR FRONTEND SOFTWARE ENGINEER 프론트엔드 개발자',\n",
       " 'BACK END ENGINEER',\n",
       " 'FRONT END MOBILE ENGINEER',\n",
       " '풀 스택 개발자 PHP',\n",
       " '프론트엔드 개발자',\n",
       " '개발 팀 CTO',\n",
       " '백엔드 엔지니어 모집',\n",
       " '데이터 엔지니어 모집 명',\n",
       " '스타트업 전문 개발 사 기술 영업 채용',\n",
       " 'REACT FRONT END 웹개발자 채용',\n",
       " 'DJANGO BACK END 웹개발자 채용',\n",
       " 'REACT NATIVE FIREBASE 개발자 채용',\n",
       " '빅인 BACKEND DEVELOPER 채용',\n",
       " '빅인 DATA ENGINEERING 채용',\n",
       " '빅인 FRONTEND DEVELOPER 채용',\n",
       " '음악 스타트업 CTO 백엔드 개발자',\n",
       " '격 근무 WEB 프론트엔드 개발자',\n",
       " 'IOS 개발자 채용 산업 기능 요원 포함',\n",
       " '항공권 검색 엔진 개발자 채용 경력 직',\n",
       " '웹 앱 SW 개발자 채용',\n",
       " '안드로이드 개발 경력 직',\n",
       " 'PRODUCT MANAGER',\n",
       " 'MACHINE LEARNING ENGINEER',\n",
       " '메 존 펜타 모바일 앱 개발자 채용',\n",
       " '메 존 펜타 백엔드 데이터 엔지니어',\n",
       " '메 존 펜타 프론트엔드 개발자 채용',\n",
       " '메 존 펜타 프로 덕트 너 PRODUCT OWNER',\n",
       " 'JAVA JSP 웹 개발자',\n",
       " '웹 앱 개발자 채용 신입 경력',\n",
       " '백엔드 BACKEND 개발자',\n",
       " '서울시 경기도 충북 배달 앱 선정 기업 WEB ANDROID 개발자 C 개발자',\n",
       " '웹 개발자 백엔드 개발자',\n",
       " '벡엔드 개발자',\n",
       " '연봉 인상 최대 BACKEND 백엔드 개발자 경력',\n",
       " '시니어 백엔드 개발자 BACK END DEVELOPER',\n",
       " '현역 전직 보충역 신입 백엔드 개발자 BACK END DEVELOPER',\n",
       " '블록 체인 개발자 BLOCKCHAIN DEVELOPER',\n",
       " '주니어 웹 개발자 WEB DEVELOPER',\n",
       " 'BACKEND SERVER 개발자',\n",
       " 'WINDOWS CLIENT C WPF 개발자',\n",
       " '웹 개발자 프론트엔드',\n",
       " 'ROBOTICS ENGINEER STATE ESTIMATION SLAM',\n",
       " 'SOFTWARE ENGINEER',\n",
       " '프론트엔드 개발자',\n",
       " 'REACT NATIVE 개발자',\n",
       " '백엔드 개발자',\n",
       " '개발 팀',\n",
       " 'SOFTWARE TEST ENGINEER',\n",
       " '라이브 커머스 서비스 개발',\n",
       " 'FUTUREKITCHEN 퓨처 키친 IOS 개발자 IOS DEVELOPER',\n",
       " 'CONTROL ENGINEER',\n",
       " '스트리밍 서버 개발',\n",
       " '안드로이드 개발자',\n",
       " '요원 편입 전직 음성인식 합성 엔진 개발 요원 병역 특례 석사 이상',\n",
       " 'CTO',\n",
       " '웹 개발자 프론트 백 채용',\n",
       " 'MESSENGER TECH LEAD ENGINEER',\n",
       " 'BILLING TECH LEAD ENGINEER',\n",
       " 'JUNIOR SITE RELIABILITY ENGINEER',\n",
       " 'SENIOR SITE RELIABILITY ENGINEER',\n",
       " '웹개발자 FRONTEND BACKEND 개발자',\n",
       " 'DATA SCIENTIST',\n",
       " 'JUNIOR DATA ENGINEER',\n",
       " 'JUNIOR DATA SCIENTIST',\n",
       " 'EDUCATIONAL SOFTWARE ENGINEER',\n",
       " '프런트엔드 개발 인턴 신입 경력 프리랜서',\n",
       " '벡엔드 개발자 채용 인턴 신입 경력 프리랜서',\n",
       " 'AI 솔루션 개발자 인턴 신입 경력 프리랜서 가능',\n",
       " '백엔드 엔지니어',\n",
       " 'CLIENT ENGINEER',\n",
       " 'SERVER SOFTWARE ENGINEER',\n",
       " '머신 러닝 엔지니어 산업 기능 요원 복무 가능',\n",
       " 'REACTJS REACTNATIVE NODEJS PHP',\n",
       " 'IOS 개발자 채용',\n",
       " 'PHP 웹 프로그래머 과장 를 모집',\n",
       " '백엔드',\n",
       " '백엔드 개발자',\n",
       " '창업 플랫폼 창업 IT 개발 직 채용 DAB PHP',\n",
       " 'WEB FRONT END ENGINEER',\n",
       " 'DEVOPS CLOUD INFRA ENGINEER',\n",
       " '데이터 분석 경진 대회 플랫폼 개발 및 운영',\n",
       " '웹 프론트엔드 개발자 채용',\n",
       " '웹프론트 개발자 VUE JS SPA 개발 경력',\n",
       " '클라우드 플랫폼 엔지니어 경력 채용',\n",
       " '사내 전산 인프라 운영 정보 보안 사내 시스템 개발 담당 채용 사원 대리',\n",
       " '요원 편입 전직 NLP NLU 엔진 개발 요원 병역 특례 석사 이상',\n",
       " '요원 편입 전직 백엔드 개발 분야 요원 병역 특례 석사 이상',\n",
       " '요원 편입 전직 딥 러닝 R D 분야 요원 병역 특례 석사 이상',\n",
       " 'COUPANG PAY BACKEND ENGINEER PRODUCT ENGINEERING',\n",
       " 'IOS 개발자',\n",
       " 'BACKEND 개발자',\n",
       " '백엔드 개발자 PHP',\n",
       " '경력 BACK END 서버 개발자',\n",
       " '안드로이드 개발자',\n",
       " 'IOS 개발자',\n",
       " 'AI BIG DATA 엔지니어 모집',\n",
       " '퍼블리셔 프론트엔드 반응 및 UX 개발',\n",
       " '개발 프론트 서버 개발자 신입 지원 가능',\n",
       " '머신 검사 장비 SW 개발자 C C MFC',\n",
       " 'WEB 개발자',\n",
       " '링 커리어 웹 프론트엔드 개발 REACT 개발자 님',\n",
       " '링 커리어 서버 개발자',\n",
       " 'REACTNATIVE 엔지니어 채용',\n",
       " 'ANDROID FRONT END DEVELOPER',\n",
       " '웹 프론트엔드 개발자',\n",
       " '개발자',\n",
       " 'UI DB 개발자',\n",
       " '개발 네트워크 엔지니어',\n",
       " '백엔드 JAVA 서버 개발',\n",
       " '데이터 분석 및 시각',\n",
       " '신약 개발 인공 지능 기업 바이오 아이 딥 러닝 개발자',\n",
       " '추천 시스템 엔지니어 AI ENGINEER SPECIALIZED IN RECOMMENDATION SYSTEM',\n",
       " '프리 윌린 백엔드 개발자 B C',\n",
       " '응용프로그램 개발 C NODE JS 경력 사원 모집',\n",
       " '머신 러닝 엔지니어',\n",
       " '웹개발자',\n",
       " 'FRONT END 개발자 인턴 및 경력',\n",
       " 'BACK END 개발자 인턴 및 경력',\n",
       " '멋쟁이 사자 HR 플랫폼 백엔드 개발자',\n",
       " '주 멋쟁이 사자 강사 채용',\n",
       " '멋쟁이 사자 HR 플랫폼 프론트엔드 개발자',\n",
       " '백엔드 서비스 개발',\n",
       " '블록 체인 기반 신규 서비스 프론트엔드 개발자 경력 채용',\n",
       " '블록 체인 기반 신규 서비스 백엔드 개발자 경력 채용',\n",
       " 'IOS 개발자 전문 연구원 가능',\n",
       " 'BACKEND ENGINEER 요원 신규 편입 가능',\n",
       " 'ANDROID 개발자 전문 연구원 가능',\n",
       " 'MESSENGER 백엔드 개발자 JAVA KOTLIN WEBSOCKET',\n",
       " '프론트 앱 개발',\n",
       " 'MECHANICAL ENGINEER 기구설계',\n",
       " 'MECHANICAL ENGINEER C CAD FEA 소프트웨어 개발',\n",
       " 'SRE ENGINEER',\n",
       " 'PRODUCT MANAGER 주니어',\n",
       " 'SOFTWARE ENGINEER 백엔드 개발 NODE JS',\n",
       " 'PRINCIPAL BACKEND ENGINEER COUPANG EATS',\n",
       " '기획 PRODUCT OWNER',\n",
       " '프론트엔드 개발자',\n",
       " '웹 프론트엔드 엔지니어',\n",
       " 'SOFTWARE ENGINEER MACHINE LEARNING 요원 지원 가능 산업 기능 요원 보충역 지원 가능',\n",
       " 'BACK END ENGINEER 요원 산업 기능 요원 보충역 지원 가능',\n",
       " '블록 오디세이 경력 직 REACT REACT NATIVE JAVASCRIPT 개발자 모집 공고',\n",
       " 'SW ENGINEER',\n",
       " 'FRONT END DEVELOPER',\n",
       " '인프라 모니터링 및 유지관리 담당자',\n",
       " '딥 러닝 엔지니어 신입 경력',\n",
       " 'IOS 개발자',\n",
       " '시니어 웹 프론트엔드 개발자 WEB FRONT END',\n",
       " 'ANDROID 개발자',\n",
       " 'FW 프로그래머',\n",
       " 'ARCUS 서버 개발자 모집',\n",
       " '프론트엔드 개발자 병특 산업 기능 요원 가능',\n",
       " 'IOS 개발 리드',\n",
       " 'IOS 개발자 병특 산업 기능 요원 가능',\n",
       " 'DEVOPS 시니어 엔지니어',\n",
       " 'ANDROID 개발자 병특 산업 기능 요원 가능',\n",
       " '머신 러닝 엔지니어',\n",
       " '시니어 백엔드 개발자',\n",
       " 'LINUX 기반 C C 경력 개발자 모집',\n",
       " 'WINDOW 기반 자율 주행 통신 V X 관련 S W 개발자 모집',\n",
       " '상처리 IMAGE PROCESSING S W 개발 분야 신입 경력',\n",
       " '백엔드 개발자 NODE JS',\n",
       " '안드로이드 개발자',\n",
       " '웹 개발자',\n",
       " '프론트엔드 개발자 모집 경력 이상',\n",
       " '전자서명 솔루션 SI 컨설팅 담당자 모집 국내 B B',\n",
       " '보안정책 팀 전자 금융 보안 매니저',\n",
       " 'DATA ENGINEER',\n",
       " '백엔드 개발 담당자 PHP',\n",
       " '검색 개발',\n",
       " '웹 프론트엔드 개발자 시니어',\n",
       " '풀 스택 개발자 FULL STACK DEVELOPER',\n",
       " 'SENIOR SOLUTION QUALITY ENGINEER',\n",
       " '챗봇 자연어 처리 개발',\n",
       " '데이터 분석 DATA SCIENTIST',\n",
       " 'IT 콘텐츠 스타트업 플랜 위드 IOS 개발자 구합 니',\n",
       " 'JUNIOR SOLUTION QUALITY ENGINEER',\n",
       " 'IT 콘텐츠 스타트업 플랜 위드 서버 개발자 구합 니',\n",
       " '헬퍼 로보틱스 임베디드 SW 개발자 모집',\n",
       " 'DEVOPS 데브 옵스',\n",
       " '백엔드 서버 개발자 NODE JS TYPESCRIPT',\n",
       " '백엔드 개발자 경력',\n",
       " '앱 개발자 경력',\n",
       " '플랫폼 서비스 기획 APP 개발자 서버 웹개발자',\n",
       " '산업 기능 요원 웹 프론트엔드 엔지니어 신입 전직',\n",
       " '산업 기능 요원 백엔드 엔지니어 신입 전직',\n",
       " 'BACKEND DEVELOPER 백엔드 서버 개발자',\n",
       " '프론트엔드 개발자 FRONTEND DEVELOPER',\n",
       " 'DBA DATABASE ENGINEER',\n",
       " '개발 팀 안드로이드 앱 개발자',\n",
       " '개발 팀 백엔드 개발자',\n",
       " '핀 테크 기업 개발 팀 FRONT END 경력 채용',\n",
       " 'SOFTWARE ENGINEER FRONT END 신입 경력',\n",
       " '유저 선택 헤어핏 리액트 웹 프론트엔드 개발자',\n",
       " '소개팅 앱 IOS 앱 개발자 모집',\n",
       " '소개팅 앱 안드로이드 앱 개발자 모집',\n",
       " '경력 소프트웨어 개발자',\n",
       " '백엔드 엔지니어 NODEJS GRAPHQL TYPEORM',\n",
       " '크로켓 프론트엔드 웹 개발자',\n",
       " '프론트엔드 엔지니어 REACT NEXTJS',\n",
       " 'QA 엔지니어',\n",
       " 'BACK END 개발',\n",
       " 'FRONT END 개발',\n",
       " '하이브리드 앱 개발자',\n",
       " '프론트엔드 개발자 채용',\n",
       " '백엔드 개발자 채용',\n",
       " '기술 지원 담당 채용',\n",
       " '인스 테리어 프론트엔드 개발자 REACT JS',\n",
       " '인스 테리어 리액트 네이티 브 개발자',\n",
       " 'REACT REACT NATIVE 개발자 경력',\n",
       " '백엔드 개발자',\n",
       " '개발 팀 모바일 개발자 요원 가능',\n",
       " '서버 프론트엔드 개발자 요원 가능',\n",
       " '프론트엔드 FRONT END 개발자 모집',\n",
       " 'ANDROID NDK 개발자 안드로이드 앱 유지 보수 및 개발자',\n",
       " '더블 픽앤픽 IOS 개발자 채용',\n",
       " '더블 테크 리드 CTO',\n",
       " 'REACT 를 사용 프론트 앤드 개발자 분',\n",
       " '중고나라 웹 프론트엔드 개발 팀',\n",
       " '크로켓 백엔드 서버 개발자',\n",
       " 'FIRMWARE ENGINEER',\n",
       " 'ANDROID DEVELOPER',\n",
       " 'GENESISLAB 의 웹 서비스 개발',\n",
       " 'BACKEND ENGINEER',\n",
       " '중고나라 데이터 매니지먼트 리더 채용',\n",
       " '중고나라 서비스 서버 개발',\n",
       " '중고나라 모니터링 시스템 개발 전문가 채용',\n",
       " '서버 개발',\n",
       " '이미지 기반 검색 및 추천',\n",
       " '중고나라 검색 엔진 개발',\n",
       " '중고나라 IOS 개발',\n",
       " '중고나라 커머스 서비스 개발',\n",
       " '중고나라 광고 플랫폼 개발',\n",
       " '중고나라 안드로이드 개발',\n",
       " '데이터 기반 추천 서비스 개발',\n",
       " '중고나라 웹 프론트엔드 개발',\n",
       " '중고나라 DBA 개발',\n",
       " '중고나라 앱 푸시 서비스 개발',\n",
       " '중고나라 시스템 엔지니어',\n",
       " '중고나라 데이터 티스 트 전문가 채용',\n",
       " '중고나라 데이터 랩 리더 채용',\n",
       " '프론트엔드 개발자',\n",
       " '자율 주행 상처리 빅데이터 서버 앱 분야 개발자 모집',\n",
       " '빅데이터 엔지니어',\n",
       " 'REACT NATIVE REACT 프론트엔드 개발자 채용',\n",
       " '백엔드 경력 직 모집',\n",
       " '서버 풀 스택 개발자 경력 직 채용',\n",
       " '프론트엔드 개발자 경력',\n",
       " '데이터 엔지니어 경력 직 채용',\n",
       " '물류 스타트업 웹 프론트엔드 VUE JS 개발자',\n",
       " '물류 스타트업 NODE JS 백엔드 개발자 채용',\n",
       " '산업 기능 요원 병역 특례 개발자 모집 보충역 현역',\n",
       " 'B 마트 안드로이드 개발자',\n",
       " '프론트엔드 개발자 이상',\n",
       " '백엔드 개발자 이상',\n",
       " '데이터 팀 데이터 분석 티스 트',\n",
       " 'WEB 프론트엔드 개발자',\n",
       " '백엔드 웹 개발자 BACK END WEB DEVELOPER',\n",
       " '앱 개발자 리엑트네이티브',\n",
       " '머신 러닝 자연어 처리 NLP 연구원 팀 팀 모집',\n",
       " '위티 주 프론트엔드 개발자 O 명 채용',\n",
       " '프론트엔드 모바일 앱 개발자 모집',\n",
       " 'BACKEND 데이터 엔지니어 아키텍트 개발자',\n",
       " '백엔드 디벨로퍼 시니어',\n",
       " '프론트엔드 디벨로퍼 시니어',\n",
       " 'FRONTEND BACKEND 개발자',\n",
       " '웹 프론트엔드 재택근무 가능 제공 공부 시간 제공',\n",
       " '웹 프론트엔드 인턴 재택근무 및 정규직 전환 가능 재택근무 가능 제공 공부 시간 제공',\n",
       " '웹 백엔드 재택근무 가능 제공 공부 시간 제공',\n",
       " '인공 지능 OTT 풀 스택 개발자 모집 경력 정규직',\n",
       " '백엔드 개발자 BACK END ENGINEER 모집 경력 프리랜서',\n",
       " '에어 프론트 개발자 REACTJS 를 모집',\n",
       " '이스포츠 플랫폼 웹 풀 스택 개발자',\n",
       " 'QA 엔지니어 담당자',\n",
       " '주니어 백엔드 엔지니어 산업 기능 요원 보충역 전직',\n",
       " 'DEVOPS 엔지니어',\n",
       " '데이터 팀 프론트엔드 FRONT END 개발자 이상',\n",
       " '링 시스템 개발자',\n",
       " 'NLU 팀 인공 지능 서비스 개발 프론트엔드 신입',\n",
       " '서버 개발자 BACKEND SOFTWARE ENGINEER',\n",
       " '프론트엔드 엔지니어',\n",
       " '데이터 엔지니어',\n",
       " 'SECURITY ENGINEER 기술 보안',\n",
       " '주니어 백엔드 엔지니어',\n",
       " '프론트엔드 엔지니어 리더',\n",
       " '프론트엔드 엔지니어 주니어',\n",
       " '백엔드 엔지니어',\n",
       " '백엔드 DEVOPS 개발자 모집',\n",
       " 'MOBILE SOFTWARE ENGINEER',\n",
       " '커머스 IOS DEVELOPER',\n",
       " '커머스 BACKEND DEVELOPER',\n",
       " 'SOFTWARE ENGINEER',\n",
       " '음식 분석 AI 개발자 경력',\n",
       " '음식 분석 AI 개발자 신입',\n",
       " '소프트웨어 엔지니어',\n",
       " '백엔드 개발 및 서버 관리',\n",
       " '히 웹 프론트엔드 개발자',\n",
       " '히 리액트 네이티 브 ANDROID 개발자',\n",
       " '일기 안드로이드 개발자 신입 경력 를',\n",
       " '웹 프론트엔드 개발자',\n",
       " '서버 개발자',\n",
       " 'ASSISTANT SOFTWARE ENGINEER',\n",
       " 'SOFTWARE ENGINEER NEW GRADUATES EXPERIENCED',\n",
       " '파이썬 장고 웹 개발자',\n",
       " '비바 이노베이션 안드로이드 개발자 채용',\n",
       " '동거 동락 프롭 테크 WEB 개발자',\n",
       " '머신 러닝 인공 지능 개발 연구',\n",
       " '블록 체인 벡엔드 개발자 기술 리서치 포지션',\n",
       " 'DJANGO 백엔드 개발 멤버',\n",
       " '딥 러닝 컴퓨터 알고리즘 개발자',\n",
       " '리액트 개발자 채용',\n",
       " 'AI 솔루션 기업 머신 R D 팀 리더',\n",
       " 'SOFTWARE ENGINEER C OPENGL WINDOWS',\n",
       " '시공 서비스 BACKEND DEVELOPER',\n",
       " 'DBA',\n",
       " '시공 서비스 WEB FRONTEND DEVELOPER',\n",
       " '커머스 ANDROID DEVELOPER',\n",
       " '자율 주행 알고리즘 개발자',\n",
       " 'SOFTWARE ENGINEER C PYTHON',\n",
       " '주 소울 매치 안드로이드 APP 데이팅 앱 개발자 정규직 채용',\n",
       " 'IOS ENGINEER',\n",
       " '플랫 가든 선배 구합 니 BACKEND ENGINEER',\n",
       " '백엔드 개발자 신입 경력',\n",
       " '분야 인공 지능 연구원 신입 경력 산업 전문요원 가능',\n",
       " '프론트엔드 개발자 신입 경력',\n",
       " 'FRONTEND BACKEND 웹 개발자',\n",
       " '웹 개발자',\n",
       " '딥 러닝 엔지니어',\n",
       " 'ESTSECURITY C C 리눅스 소프트웨어 개발자 신입 가능',\n",
       " 'IDS BACK END JAVA 개발자',\n",
       " '이커머스 물류 스타트업 시스템 개발자 채용',\n",
       " '커머스 풀 스택 개발자',\n",
       " 'R D 연구소 응용프로그램 개발자 채용',\n",
       " 'WONDERWALL BACK END 개발자',\n",
       " 'R D 연구소 모바일 파트 채용',\n",
       " 'R D 연구소 개발자 채용',\n",
       " '채용 안내 국내 대기업 MS 서비스 운영 담당자 명 채용',\n",
       " '채용 안내 국내 대기업 데이터 엔지니어링 DATA ENGINEER 채용',\n",
       " '프론트엔드 개발자',\n",
       " 'JAVA SPRING API 개발자',\n",
       " '푸른새벽 기술 연구소 수석 채용',\n",
       " '풀 스택 개발자 경력 직 를',\n",
       " '프론트 개발자',\n",
       " '백엔드 개발자',\n",
       " '주 휴넷 JAVA 개발자 경력 직 모집',\n",
       " 'REACT 프론트엔드 개발자',\n",
       " '강남 지역 빅데이터 분석 개발자',\n",
       " '프론트엔드 FRONT END DEVELOPER',\n",
       " 'MESSENGER 백엔드 개발자 PHP REST API',\n",
       " 'JAVA 백엔드 개발 담당자',\n",
       " '안드로이드 앱 개발 담당자',\n",
       " '강남 지역 빅데이터 인공 지능 분석 논문 연구',\n",
       " '강남 지역 빅데이터 분석 추론 개발자 데이터 티스 트',\n",
       " '개발 총괄 책임자 CTO',\n",
       " '프론트엔드 개발자 채용 산업 기능 요원 가능',\n",
       " 'IOS 앱 개발자 산업 기능 요원 가능',\n",
       " '플랫폼 백엔드 개발자 채용 산업 기능 요원 가능',\n",
       " 'ANDROID 앱 개발자 산업 기능 요원 가능',\n",
       " '파이썬 웹 개발자',\n",
       " 'AI 연구원 머신 러닝',\n",
       " 'TAXONOMY AND DATA ANALYTICS CONSULTANT',\n",
       " 'PHP 개발자',\n",
       " '글로벌 이모티콘 솔루션 경력 직 팀 급 IOS 엔지니어 를',\n",
       " '글로벌 이모티콘 솔루션 경력 직 팀 급 ANDROID 엔지니어 를',\n",
       " '블록 체인 L 핀 테크 DEFI 차익거래 위 스마트 컨트랙트 개발자',\n",
       " '커머스 기반 플랫폼 운영 및 고도화 담당자 모집',\n",
       " '백엔드 개발자',\n",
       " '프론트엔드 개발자',\n",
       " '페이 워 TYPESCRIPT NODE JS 백엔드 개발자 채용',\n",
       " '주식 인 플루 와 커뮤니티 플랫폼 개발 분 CTO CO FOUNDER',\n",
       " 'REACT NATIVE 엔지니어',\n",
       " '웹 페이지 개발자',\n",
       " 'IOS 앱 개발자',\n",
       " '사업 팀 JAVA 서버 백엔드 개발자',\n",
       " 'WONDERWALL FRONT END 개발자',\n",
       " 'WEB CLIENT DEVELOPER',\n",
       " '사내 시스템 개발자',\n",
       " '데브 옵스 엔지니어',\n",
       " '백엔드 개발자',\n",
       " 'ANDROID 개발자',\n",
       " '메시 징 서버 개발자',\n",
       " '프론트엔드 개발자 WEB CLIENT 프롭 테크 스타트업 점프',\n",
       " '풀 스택 개발자',\n",
       " '백엔드 개발자',\n",
       " 'DJANGO 풀 스택 개발자 산업 기능 요원',\n",
       " '프론트엔드 신입 경력 개발자',\n",
       " 'QA 담당자',\n",
       " '백엔드 신입 경력 개발자',\n",
       " '모바일 차량 관리 위 서비스 마이클 안드로이드 개발자 경력 모집',\n",
       " '모바일 차량 관리 위 서비스 마이클 서버 개발자 경력 모집',\n",
       " '펄핏 신발 사이즈 추천 서비스 PERFITT 데이터 엔지니어',\n",
       " 'SITE RELIABLE ENGINEER SRE',\n",
       " '콘텐츠 IOS DEVELOPER',\n",
       " 'LEAD TECHNICAL SOLUTION ENGINEER',\n",
       " 'LYCLE WEB FRONT 개발자 REACT',\n",
       " 'BACK END JAVA 개발자',\n",
       " 'FRONT END REACT 개발자',\n",
       " 'IOS 개발 인턴 경력 채용',\n",
       " 'ANDROID 개발 인턴 경력 채용',\n",
       " 'D 테크니컬 아티스트',\n",
       " 'REACT NATIVE DEVELOPER 신입 경력',\n",
       " '얼굴 비율 측정 앱 개발 가능 프로그래머',\n",
       " '동남아 결제 서비스 개발자 이상',\n",
       " '앤드 개발자',\n",
       " '콘텐츠 ANDROID DEVELOPER',\n",
       " 'CAN LAB 안드로이드 개발자',\n",
       " '솔드아웃 BACK END 개발자',\n",
       " 'BACKEND DEVELOPER 산업 기능 요원',\n",
       " '콘텐츠 BACKEND DEVELOPER',\n",
       " 'SR DATA ENGINEER',\n",
       " '파이썬 앤드 개발자',\n",
       " '핀 테크 기업 나무 의 IOS 개발자',\n",
       " '게임 클라이언트 개발자',\n",
       " '안드로이드 개발자 모집',\n",
       " '헬로 마켓 백엔드 개발자 JAVA SPRING 채용',\n",
       " 'OZIC 개발자',\n",
       " '고민 수 팀 우선 개발자',\n",
       " 'AR UNITY 개발자',\n",
       " '클라우드 서버 개발자',\n",
       " '뷰티 헬 스케 시장 선도 기업 포터 프론트 개발자',\n",
       " 'B B 유통 관리 플랫폼 PHP 개발자',\n",
       " '시니어 웹 개발자 VUE JS',\n",
       " 'FRONT END 개발자 VUE JS',\n",
       " '백엔드 개발자 JAVA',\n",
       " 'B B 오픈마켓 PHP 개발자',\n",
       " '서비스 개발 모바일 IOS',\n",
       " 'GLOBAL DEVELOPMENT PARTNER AI ADTECH STARTUP',\n",
       " '개발 직 플랫폼 개발자',\n",
       " '개발 직 풀 스택 개발자',\n",
       " 'FRONTEND BACKEND DEVELOPER FULLSTACK JS DEVELOPER 프론트엔드 개발자 폴 스택 개발자',\n",
       " '직톡 백엔드 개발자',\n",
       " '콘텐츠 WEB FRONTEND DEVELOPER',\n",
       " 'BACKEND SOFTWARE ENGINEER',\n",
       " 'FULL STACK SOFTWARE ENGINEER',\n",
       " '벡엔드 개발자 채용 경력 리더',\n",
       " 'REACT NATIVE 개발자 신입 경력',\n",
       " 'NO 자동차 출장 정비 플랫폼 런 오일 백엔드 어플리케이션 개발자 인재 입',\n",
       " 'NO 자동차 출장 정비 플랫폼 런 오일 프론트엔드 웹 어플리케이션 개발자 인재 입',\n",
       " 'NO 자동차 출장 정비 플랫폼 런 오일 IOS 어플리케이션 개발자 인재 입',\n",
       " 'NO 자동차 출장 정비 플랫폼 런 오일 안드로이드 어플리케이션 개발자 인재 입',\n",
       " 'BACK END 개발자',\n",
       " 'WEB FRONT END 개발자',\n",
       " '데이터 티스 트',\n",
       " '헬 스케 핀 테크 백엔드 C ASP 개발자 신규 채용',\n",
       " 'VR 영상 제작',\n",
       " 'FRONT END ENGINEER',\n",
       " 'INFRA SYSTEM ENGINEER',\n",
       " '오픈 플랜 BACK END DEVELOPER 우수 인재',\n",
       " 'JAVA 개발 공통 플랫폼',\n",
       " '운동 데이터 분석 위 데이터 티스 트',\n",
       " '회원 플랫폼 팀 JUNIOR BACK END DEVELOPER',\n",
       " '시니어 프론트 개발자',\n",
       " 'BACK END ENGINEER PYTHON 이상',\n",
       " '토글 프론트엔드 REACT 개발자 인재 채용',\n",
       " '스 일 개발자',\n",
       " '노스페이스 상반기 채용 S W 개발',\n",
       " '머신 러닝 엔지니어',\n",
       " '프론트엔드 프로그래머',\n",
       " '백엔드 개발자 모집',\n",
       " '카 데미 웹 프론트 엔드 개발자 채용 공고 채용 시 마감',\n",
       " '프론트엔드 개발자 VUE JS 채용',\n",
       " '웹 프로그래밍 개발자 BACK END 모집',\n",
       " '영상 그래픽 분야 SW 개발자 모집',\n",
       " '경력 독일 완성 차 인포테인먼트 시스템 테 스팅 위 개발자 및 QA 엔지니어',\n",
       " '보안 솔루션 개발',\n",
       " '안드로이드 모바일 앱 개발자 모집',\n",
       " '개인 맞춤 취미 자기계발 상품 추천 서비스 코알라 개발 담당자 프런트엔드 개발자 인 백엔드 개발자 인',\n",
       " '프론트엔드 개발자',\n",
       " '음성 인식 엔지니어',\n",
       " '컴퓨터 엔지니어',\n",
       " '컴퓨터 머신 러닝 리 처 엔지니어 딥 러닝 제외',\n",
       " '물류 배송 BACKEND DEVELOPER',\n",
       " 'DEVOPS ENGINEER',\n",
       " 'A I ENGINE DEVELOPER',\n",
       " '모바일 팀 리더',\n",
       " 'A I ENGINE DEVELOPER 인공 지능 엔진 개발',\n",
       " 'MOBILE APP DEVELOPER IOS ANDROID 앱 개발자',\n",
       " '프론트엔드 팀',\n",
       " '백엔드 개발',\n",
       " 'JR 서버 개발자',\n",
       " '패션 플랫폼 CTO 역할 참여 창립 멤버 분 참여 외주 개발 진행',\n",
       " '백엔드 개발자',\n",
       " '프론트엔드 개발자',\n",
       " 'CTO FULL STACK 백엔드 DJANGO OR JAVA OR NODE JS 프론트엔드 REACT JS REACT NATIVE 개발자',\n",
       " 'ROBOTICS SOFTWARE ENGINEER',\n",
       " '웹 프론트엔드 개발자 VUE',\n",
       " 'AI 연구원',\n",
       " '백엔드 엔지니어',\n",
       " '리드 백엔드 엔지니어',\n",
       " '풀 스택 웹 개발자 REACT NODE JS',\n",
       " '모바일 IOS 및 안드로이드 개발자',\n",
       " '개발 서버 개발자',\n",
       " '웹 퍼블리셔',\n",
       " '컬 아이피 의료 상처리 WINDOWS S W 개발자 모집',\n",
       " '컬 아이피 춘천 연구개발 분야 개발자 모집',\n",
       " '인공 지능 A I 연구 개발자 채용 인턴 신입 경력 산업 기능 요원 포함',\n",
       " '안드로이드 개발자 채용 ANDROID 산업 기능 요원 포함',\n",
       " '상 채용 키 사이드 블록 체인 WEB SERVICE 개발자 모집',\n",
       " '비트 홀 주 JUNIOR SOFTWARE DEVELOPER 구인',\n",
       " '모바일 앱 웹 개발 경력 사원 채용 WEB ANDROID IOS',\n",
       " 'AI 관심 백엔드 개발 경력 모집',\n",
       " '웹 서비스 개발자',\n",
       " 'UNITY D 를 활용 AR 교육 컨텐츠 개발',\n",
       " 'IOS 개발자',\n",
       " 'APP 개발',\n",
       " 'WEB 개발',\n",
       " '블록 체인 서비스 백엔드 개발자',\n",
       " '블록 체인 서비스 프론트엔드 개발자',\n",
       " 'PHP 자바 개발자 채용',\n",
       " '전기 아이피 프론트 개발자',\n",
       " '전기 아이피 DBA',\n",
       " '전기 아이피 게임 QA',\n",
       " '웹 개발',\n",
       " 'FULL STACK TYPESCRIPT 개발자',\n",
       " '임베디드 보드 제어 개발자',\n",
       " 'SOFTWARE ENGINEER CTO 지원 가능',\n",
       " '웹 시스템 플랫폼 개발자 계약 직',\n",
       " '주 테라 젠 바이오 프론트엔드 웹개발자 PHP PYTHON 채용',\n",
       " '스마트 모빌리티 MAAS 플랫폼 서비스 만 IOS 어플리케이션 개발자',\n",
       " 'GUI 소프트웨어 개발 신입 및 경력 모집',\n",
       " '웹 퍼블리셔 고수',\n",
       " '연구개발 JAVASCRIPT C 소프트웨어 개발자',\n",
       " '모바일 보안 솔루션 개발 병특 가능 산업 기능 요원 보충역 OR 전직 요원',\n",
       " '헬스 앤 메디슨 HYBRID MOBILE DEVELOPER 를',\n",
       " '헬스 앤 메디슨 ANDROID DEVELOPER 를',\n",
       " '헬스 앤 메디슨 JAVA MVC 개발자',\n",
       " '헬스 앤 메디슨 LEAD DEVELOPER 를',\n",
       " '웹개발자 신입 경력 채용 O O',\n",
       " '데이터 티스 트',\n",
       " 'CORE ENGINEER',\n",
       " 'MOBILE ENGINEER',\n",
       " 'ESTSOFT IT 시스템 엔지니어',\n",
       " '웹 개발',\n",
       " 'ESTSOFT QA 담당자',\n",
       " '데이터 엔지니어 주니어',\n",
       " '셀러 파트 백엔드 개발자',\n",
       " 'DEV RELATIONS ENGINEER',\n",
       " '주 트 G LAB 연구원 채용',\n",
       " 'DEEP LEARNING 기반 BACK END 시스템 운영 MLOPS ENGINEER',\n",
       " 'DEEP LEARNING ENGINEER AI 엔진 구축',\n",
       " 'FULL STACK 개발자',\n",
       " '요원 채용',\n",
       " '웹 퍼블리셔 모집',\n",
       " 'UNITY 개발자',\n",
       " '웹 개발자',\n",
       " 'ANDROID IOS 개발자 공고',\n",
       " '웹개발자',\n",
       " '웹 개발자 LARAVEL VUE 를',\n",
       " 'CRM DW ISP 컨설팅 분석 설계 개발 정규직 채용',\n",
       " '안드로이드 디벨로퍼 ANDROID DEVELOPER',\n",
       " '열정 능력 DATA SCIENTIST',\n",
       " '인 플루 마케팅 플랫폼 백엔드 개발자',\n",
       " 'CAN LAB FRONTEND DEVELOPER',\n",
       " 'CAN LAB IOS DEVELOPER',\n",
       " '백엔드 서버 개발자',\n",
       " '서버 개발자',\n",
       " '프론트 앤드 개발자',\n",
       " '메이크 스타 프론트 소프트웨어 엔지니어 경력',\n",
       " '메이크 스타 프론트 소프트웨어 엔지니어 경력',\n",
       " '메이크 스타 백엔드 소프트웨어 엔지니어 경력',\n",
       " '웹 프론트 개발자 경력',\n",
       " '웹 백엔드 개발자 경력',\n",
       " '미래 사업 부문 내부 시스템 개발자 채용',\n",
       " 'QA 엔지니어',\n",
       " '서버 개발자 PYTHON',\n",
       " 'DATA ENGINEER',\n",
       " '프론트엔드 개발자',\n",
       " '머신 러닝 리서치 티스 트',\n",
       " '경력 웹 프론트엔드 엔지니어',\n",
       " '연봉 인상 최대 APP 모바일 앱 개발자 경력',\n",
       " '브랜디 백엔드 개발자',\n",
       " 'CLOUD ENGINEER 클라우드 엔지니어 이상',\n",
       " '백엔드 개발자',\n",
       " 'BACK END 개발자 NODE JS',\n",
       " '안드로이드 앱 개발자',\n",
       " 'IOT 하드웨어 개발',\n",
       " '핀 테크 앱 개발자',\n",
       " '자동차튜닝 D 가상 체험 및 시공사 매칭 서비스 어플 개발자',\n",
       " '모빌리티 서비스 프로 덕트팀 웹 개발 멤버 분',\n",
       " '미니맵 REACT JS 개발자',\n",
       " '틴캔 TIN CAN 소셜 라디오 컴퍼니 IOS 개발자',\n",
       " '틴캔 TIN CAN 소셜 라디오 컴퍼니 ANDROID 개발자',\n",
       " 'IOS 가족',\n",
       " 'BACK END 개발자 채용 모집',\n",
       " 'FRONT END 개발자 채용 모집',\n",
       " 'JUNIOR DROOT BACK END DEVELOPER',\n",
       " 'SW 개발 연구원 SW DEVELOPMENT RESEARCHER',\n",
       " '서버 개발자 모바일 자산 관리 서비스 뱅큐 서버 개발자 경력 직',\n",
       " '웹 프론트엔드 개발자',\n",
       " '모바일 프론트엔드 개발자 FLUTTER',\n",
       " 'FRONT END 개발자 채용',\n",
       " '빅데이터 기반 K POP 플랫폼 만 BACK END 개발자',\n",
       " '소프트웨어 개발 엔지니어',\n",
       " 'QA',\n",
       " '외국 안면 인식 기술 SW 유지 보수 및 기술 지원',\n",
       " '자바 개발자 앤드 웹개발자 모집',\n",
       " 'REACT NATIVE CLIENT 개발자',\n",
       " 'IOS 개발자 채용',\n",
       " '백엔드 개발 JAVA SPRING 채용',\n",
       " '프론트엔드 개발 REACT WEB 채용',\n",
       " 'ANDROID 개발자 채용',\n",
       " 'REACT NATIVE 개발자',\n",
       " '백엔드 개발자',\n",
       " '프론트엔드 개발자',\n",
       " '주 민트 팟 IOS 개발자 경력 채용',\n",
       " '주 민트 팟 본사 SI 개발 팀 채용',\n",
       " '퍼블리셔 경력 직 채용',\n",
       " '프론트엔드 경력 직 채용',\n",
       " '백엔드 엔지니어',\n",
       " '프론트엔드 엔지니어',\n",
       " '빅워크루 IOS 개발자',\n",
       " 'QA TESTER',\n",
       " 'DEVOPS LEAD',\n",
       " 'ANDROID DEVELOPER',\n",
       " '데이터 엔지니어 DATA ENGINEER',\n",
       " '챌린저스 앱 프론트 개발자',\n",
       " 'DEVOPS ENGINEER',\n",
       " 'BACKEND DEVELOPER',\n",
       " '안드로이드 ANDROID 개발',\n",
       " '백엔드 BACKEND 개발',\n",
       " '빅워크루 안드로이드 개발자',\n",
       " 'TECH MANAGER BACK END ENGINEER',\n",
       " '시니어 백엔드 엔지니어 SENIOR BACK END ENGINEER',\n",
       " '주니어 웹 프론트엔드 엔지니어 JUNIOR WEB FRONT END ENGINEER',\n",
       " 'TECH MANAGER SITE RELIABILITY ENGINEER SRE',\n",
       " 'SENIOR DATA SCIENTIST',\n",
       " 'TECH MANAGER QUALITY',\n",
       " 'TECH MANAGER DATA SCIENTIST',\n",
       " 'JUNIOR DATA SCIENTIST',\n",
       " 'TECH MANAGER WEB FRONT END ENGINEER',\n",
       " '주니어 백엔드 엔지니어 JUNIOR BACK END ENGINEER',\n",
       " '시니어 웹 프론트엔드 엔지니어 SENIOR WEB FRONT END ENGINEER',\n",
       " '소프트웨어 개발자',\n",
       " 'TECH LEAD FULL STACK ENGINEER',\n",
       " 'CUCURBITA 내일 출근 시작 WEB 개발자 목',\n",
       " 'PHP 웹개발자 채용',\n",
       " '딥 러닝 엔지니어 석사 이상',\n",
       " 'R D DEEP LEARNING S W ENGINEER',\n",
       " '시스템 서버 구축 및 SYSTEM INTEGRATION',\n",
       " 'IOS 개발',\n",
       " 'DATA SCIENTIST',\n",
       " 'WEBRTC 엔지니어',\n",
       " '프로그램 및 앱 개발자',\n",
       " '프론트엔드 개발자 FRONTEND ENGINEER',\n",
       " 'IOS ENGINEER',\n",
       " '웹개발자',\n",
       " '안드로이드 개발자',\n",
       " '백엔드 서버 개발자 채용 IOT 코어 서버 개발',\n",
       " '서버 개발자 경력 직 신규 채용 JAVA SPRING',\n",
       " '모바일 앱 개발자',\n",
       " '라이브 데이터 DATA ENGINEER 를 신입 경력',\n",
       " 'IOS APPLICATION 개발자',\n",
       " '프론트엔드 엔지니어 웹 퍼블리셔',\n",
       " '경력 기술 연구소 프론트 앤드 개발자 정규직 채용',\n",
       " 'S W 개발자 모바일 어플리케이션',\n",
       " '더 커머스 퍼블리셔 프론트엔드 개발자 모집',\n",
       " '위계 조직 역할 조직 일 SW 개발자 및 관리자 지원',\n",
       " '안드로이드 네이티 브 개발자',\n",
       " '웹 앱 서비스 팀 급 개발자 모집',\n",
       " '신발 연구소 백엔드 개발자 NODE JS GRAPHQL',\n",
       " '신발 연구소 리액트 네이티 브 REACT NATIVE 개발자',\n",
       " '신발 연구소 리액트 REACT 개발자',\n",
       " '백엔드 개발자 BACKEND ENGINEER',\n",
       " '데이터 분석 티스 트',\n",
       " '웹 프론트엔드 개발자',\n",
       " '게임 클라이언트 프로그래머',\n",
       " '프론트엔드 개발자 REACT NATIVE',\n",
       " '클라이언트 개발자',\n",
       " 'FULL STACK 경력 직 백엔드 NODE JS 프론트엔드 REACT JS 풀 스택 개발자',\n",
       " '대전 지역 기업 레드 윗 전문 연구원 개발자 및 일반 개발 팀 모집',\n",
       " '프론트 개발자',\n",
       " '플레이 키 보드 IOS 개발자 산업 기능 요원 보충역 지원 가능',\n",
       " '어플리케이션 ANDROID 개발자 채용',\n",
       " '화룡 점정 임박 파도 팀 마지막 퍼즐 조각 킹 제너럴 개발자',\n",
       " '백엔드 개발자 명 경력 이상',\n",
       " '주 앱플러 안드로이드 개발자 경력 모집',\n",
       " 'IOS 개발자 정규직 모집 경력',\n",
       " '주 앱플러 서버 백엔드 웹 프론트 개발자 모집',\n",
       " '응용소프트웨어 JAVA 개발자 웹 프로그래머 경력 인 APP 개발자 안드로이드 아이폰 신입 인',\n",
       " 'IOS ANDROID APP REACT NATIVE 프론트엔드 개발자',\n",
       " 'SW 개발 BACKEND',\n",
       " '모빌 테크 기술 개발 팀 SW 개발 신입 경력 사원 채용',\n",
       " '유니티 D POINTCLOUD AR 개발자 모집',\n",
       " '모빌 테크 기술 개발 팀 센서 융합 연구원 모집',\n",
       " '앱 웹 개발자 모집',\n",
       " '웹 백엔드 개발자 WEB BACK END DEVELOPER',\n",
       " '급구 전자문서 시스템 JAVA 개발',\n",
       " 'ST UNITAS SYSTEM ENGINEER 경력 모집',\n",
       " '서버 팀',\n",
       " '데이터 엔지니어',\n",
       " '안드로이드 앱 개발',\n",
       " '웹 개발',\n",
       " '서버 개발',\n",
       " 'TADA 정산 재무 시스템 개발',\n",
       " '안드로이드 개발자',\n",
       " '윌 안드로이드 앱 개발자',\n",
       " '윌 IOS 앱 개발자',\n",
       " '윌 프론트엔드 개발자',\n",
       " '윌 백엔드 개발자',\n",
       " '소프트웨어 엔지니어 경력 채용',\n",
       " '크라운 랩스 웹서비스 개발자 채용 사업 분야',\n",
       " '서버 개발자',\n",
       " 'ANDROID 개발자',\n",
       " '영상 서버 개발자',\n",
       " '프론트엔드 개발자',\n",
       " '모바일 개발자 IOS ANDROID',\n",
       " '시스템 관리자 SA 팀',\n",
       " 'DBA',\n",
       " '안드로이드 앱 개발자',\n",
       " 'PHP 웹 개발 채용 공고',\n",
       " '리액트 네이티 브 개발자',\n",
       " '신입 머신 러닝 연구원',\n",
       " '신입 프론트엔드 개발자',\n",
       " '자바 JAVA JSP 개발자',\n",
       " 'IT COMPLIANCE MANAGER',\n",
       " 'TADA 정보보호 담당자',\n",
       " '경력 백엔드 개발자',\n",
       " 'STT ENGINEER',\n",
       " '게임 유저 매칭 플랫폼 앤드 개발',\n",
       " '백엔드 개발 담당자 PHP',\n",
       " '결혼 어플 자기야 WEB APP 안드로이드 IOS 개발자',\n",
       " '백엔드 개발자',\n",
       " '백엔드 개발자',\n",
       " 'PHP 웹 개발자',\n",
       " '서버 개발자',\n",
       " 'BACKEND 개발자 모집',\n",
       " 'FRONTEND 개발자 모집',\n",
       " '프론트엔드 개발자 플러터',\n",
       " '소프트웨어 개발자 모집 DJANGO REST FRAMEWORK REACT',\n",
       " 'TADA 백오피스 개발',\n",
       " '프런트엔드 개발자 이상 경력',\n",
       " 'SOFTWARE ENGINEER DEEP LEARNING',\n",
       " 'SOFTWARE ENGINEER PERCEPTION',\n",
       " '카메라 기반 휴대폰 앱 개발자 IOS ANDROID',\n",
       " '인공 지능 반려동물 관리 플랫폼 백엔드 개발자',\n",
       " '프론트엔드 개발자 요원 가능',\n",
       " '백엔드 개발자 요원 가능',\n",
       " 'ANDROID 개발자',\n",
       " '웹 개발자 고용',\n",
       " '백엔드 엔지니어 서버 개발자',\n",
       " '프론트엔드 엔지니어',\n",
       " '데이터 엔지니어',\n",
       " 'REACT SVELTE WEB 개발자',\n",
       " '백엔드 BACKEND 개발자 RUBY RAILS REST API AWS K S',\n",
       " '정보보안 담당자 팀 급 정보 최고 담당자 CISO',\n",
       " 'REACT REACT NATIVE 프론트 개발자',\n",
       " '백엔드 BACKEND 개발자 PYTHON DJANGO GRAPHQL AWS K S',\n",
       " '헤브론 스타 텍 풀 스택 FULL STACK 개발 리드 채용 채용 시 마감',\n",
       " '안드로이드 개발 및 WEB APP 유지 보수 담당자 모집',\n",
       " '안드로이드 개발자',\n",
       " '물류 WMS TMS 설계 개발',\n",
       " '놀이 발견 안드로이드 개발자 KOTLIN',\n",
       " '놀이 발견 APP API 개발 PYTHON DJANGO',\n",
       " '백엔드 엔지니어',\n",
       " '블록 체인 백엔드 개발자',\n",
       " '로우 코퍼레이션 MOBILE IOS APP ENGINEER',\n",
       " '로우 코퍼레이션 FRONT END ENGINEER',\n",
       " '놀이 발견 O O 플랫폼 결제 정산 프로세스 개발',\n",
       " '놀이 발견 플랫폼 API 개발 PYTHON DJANGO',\n",
       " '학습 앱 개발자',\n",
       " '앱 개발자',\n",
       " 'JAVA 백엔드 개발자 경력 직 채용 JAVA SPRING SPRING BOOT',\n",
       " 'DEVOPS DEVELOPMENT OPERATIONS 경력 직 채용 공고',\n",
       " '웹개발자',\n",
       " '쇼핑몰 광고 입찰 자동 프로그램 및 크롤 링 기반 상품 등록 프로그램 개발',\n",
       " '앱 개발자 코어 멤버',\n",
       " '백엔드 개발자 AI 피트니스 서비스 플랫폼',\n",
       " '서버 개발자 채용',\n",
       " '인공 지능 머신 연구개발',\n",
       " '서버 개발자 채용 공고 PHP HTML 백엔드 프론트엔드',\n",
       " '경력 상반기 라이언 로켓 채용 백엔드',\n",
       " '에이 치비 엠피 백엔드 엔지니어 경력 모집',\n",
       " '힙합 퍼 백엔드 서비스 개발자 님',\n",
       " '클레이튼 파트너 사 PROJECT WITH 블록 체인 앱 개발자 모집',\n",
       " '개발자',\n",
       " '앱 개발자 AI 기반 골프 스윙 분석 플랫폼',\n",
       " 'COMPUTER VISION ENGINEER',\n",
       " '차세대 주차 솔루션 개발 팀 모집',\n",
       " 'ICT 서비스 본부 신입 정규직 채용',\n",
       " 'A I BIG DATA CLOUD 기반 소프트웨어 직',\n",
       " '백엔드 개발자 채용',\n",
       " '웹 퍼블리셔 UI UX MARKUP DEVELOPER',\n",
       " '파이썬 개발자 PYTHON DEVELOPER 소프트웨어 엔지니어',\n",
       " '로우 코퍼레이션 BACK END ENGINEER',\n",
       " 'BACK END DEVELOPER 백엔드 개발자 앤드 개발자',\n",
       " 'FRONT END DEVELOPER 프론트엔드 개발자 채용',\n",
       " 'BACK END 개발자 채용 DJANGO 개발 경력 이상 팀 급',\n",
       " '글로벌 APP 서비스 WINDOWS APP 엔지니어 채용',\n",
       " '영업 자바 개발자 DB 모델 러 분석 모델 러 채용',\n",
       " '디지털 치료 기기 어플 QA',\n",
       " 'WEB DEVELOPER BACK END 백엔드',\n",
       " '백엔드 개발자',\n",
       " '인공 지능 AI 개발자',\n",
       " '웹 개발 담당자 채용',\n",
       " '백엔드 개발자 BACK END ENGINEER',\n",
       " '데이터 검수 개발자',\n",
       " '프론트 엔드 개발자 FRONT END ENGINEER',\n",
       " '상처리 AI 개발자 딥 러닝 머신 러닝 개발자',\n",
       " '인공 지능 AI 컴퓨터 드론 로봇 머신 정밀 제어 핵심 SW 개발자 채용',\n",
       " '정규직 신입 가능 파이썬 라이브러리 개발자',\n",
       " '정규직 신입 가능 데이터 분석',\n",
       " '정규직 신입 가능 데이터 엔지니어',\n",
       " 'KT 그룹 업계 위 주 나스 미디어 웹 개발 채용',\n",
       " 'KT 그룹 업계 위 주 나스 미디어 웹 개발 채용',\n",
       " '모바일 웹 개발자',\n",
       " 'REACT NATIVE 개발자 구인 모바일 패션 앱',\n",
       " '이커머스 플랫폼 개발자',\n",
       " '이커머스 프론트엔드 개발자',\n",
       " '커머스 서버 개발 전문가',\n",
       " 'IOS 앱 개발',\n",
       " 'CTO',\n",
       " 'FULL STACK ENGINEER',\n",
       " '부산 웹 백엔드 경력 채용',\n",
       " 'JAVA SPRING 이커머스 시니어 개발자 채용',\n",
       " '웹개발자 세계 명품 시장 타겟팅 플랫폼 웹개발자 채용',\n",
       " 'FRONT END DEVELOPER',\n",
       " '웹 서버 분야 개발자 인턴 신입 경력',\n",
       " '주 델미텐츠 웹 프론트 개발자 경력 채용',\n",
       " '트레져 헌터 백엔드 개발자',\n",
       " 'DATA ENGINEER',\n",
       " '정규직 경력 웹 응용 프로그램 개발자 채용',\n",
       " 'FRONTEND DEVELOPER',\n",
       " 'BACK END SOFTWARE ENGINEER',\n",
       " '로 인텔리전스 개발 팀 전직 채용',\n",
       " 'JUNIOR FINANCIAL SOFTWARE ENGINEER',\n",
       " '체외 진단 의료기기 소프트웨어 개발 부문 신입 경력',\n",
       " '가상 화폐 암호 화폐 트레이딩 프로그램 개발자 구인',\n",
       " '피처링 BACKEND 웹개발자 채용',\n",
       " '피처링 FRONTEND 개발자 채용',\n",
       " 'JAVA 웹 개발',\n",
       " '대규모 삼성 전자 시스템 운영 DB 분석 담당 채용',\n",
       " 'CRYPTOPARADISE BACK END JUNIOR DEVELOPER',\n",
       " 'CRYPTOPARADISE FRONT END JUNIOR DEVELOPER',\n",
       " '펌웨어 개발 및 앱 개발자',\n",
       " 'BACKEND ENGINEER 채용 JAVA SPRING',\n",
       " 'MOBILE ENGINEER ANDROID IOS FLUTTER 채용',\n",
       " 'FRONTEND ENGINEER 채용 REACT OR VUE OR ANGULAR FRONT',\n",
       " '블록 체인 핀 테크 디지털 자산 관리 플랫폼 BACK END FRONT END 개발자',\n",
       " '데이터베이스 소프트웨어 웹 개발자 모집 백엔드',\n",
       " '데이터베이스 소프트웨어 경력 직 개발자 모집 C C',\n",
       " 'CLOUD 서비스 개발 담당자 모집',\n",
       " '프론트엔드 개발',\n",
       " '클라우드 엔지니어 인프라',\n",
       " 'SENIOR SYSTEM ENGINEER',\n",
       " '그로잉세일즈 FRONT END 개발자 모집',\n",
       " 'FOOD COMMERCE 웹 퍼블리셔',\n",
       " '백엔드 개발자 PYTHON DJANGO 신입 지원 가능',\n",
       " '백엔드 개발자 SPRING AWS',\n",
       " 'IOS 앱 개발자',\n",
       " 'AI PLATFORM BACKEND ENGINEER',\n",
       " '클라우드 엔지니어 팀 급 IT 인프라 클라우드 개발',\n",
       " '데브 옵스 DEVOPS 엔지니어',\n",
       " '데이터 매니지먼트 팀',\n",
       " '검색 엔진 개발 전문가',\n",
       " '클라이언트 개발자',\n",
       " '서버 개발자',\n",
       " 'FRONT END ENGINEER 요원 산업 기능 요원 보충역 지원 가능',\n",
       " '웹 앱 프론트 개발 담당자 모집 글로벌 버젼',\n",
       " '개발자 모집 인턴 주니어 지원 가능',\n",
       " '백엔드 서버 개발 및 데이터 처리 PYTHON',\n",
       " '데브 옵스 DEVOPS 엔지니어 채용',\n",
       " 'APP 개발자 채용',\n",
       " 'FRONT END 개발자',\n",
       " '다짐 백엔드 개발자 채용 중 이상',\n",
       " '다짐 프론트엔드 개발자 채용 중 이상',\n",
       " '신입 경력 COMPUTER VISION 자율 주행 엔지니어',\n",
       " 'NEUBILITY SLAM ROBOTICS SW ENGINEER',\n",
       " 'NEUBILITY DEEP RL ENGINEER',\n",
       " '서핏 프론트엔드 엔지니어 VUE JS',\n",
       " '프론트엔드 개발자 REACT TS 채용',\n",
       " '안드로이드 개발 전문가',\n",
       " '구글 클라우드 플랫폼 엔지니어 데이터 플랫폼 구축 및 운영',\n",
       " 'AWS 클라우드 기반 오픈소스 개발자 JS TS PYTHON 위주',\n",
       " 'AI 딥 러닝 플랫폼 위 백엔드 엔지니어',\n",
       " 'AI 딥 러닝 엔지니어',\n",
       " 'AI 딥 러닝 플랫폼 위 프런트엔드 엔지니어',\n",
       " '주식회사 꾼 개발자 신입 경력 채용 공고',\n",
       " '반려 생활 반려동물 스타트업 REACT NATIVE 개발자',\n",
       " '신입 개발자 채용 SOFTWARE ENGINEER',\n",
       " 'SOFTWARE ENGINEER DATA',\n",
       " 'IOS 개발 전문가',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = []\n",
    "label = []\n",
    "for index,title in tqdm(enumerate(total_df['title'])) : #토큰\n",
    "    okt_title = converter.pos(title)\n",
    "    sentences.append(' '.join([tup[0].upper() for tup in okt_title if tup[1] == 'Noun' or tup[1] == 'Alpha']))\n",
    "\n",
    "for index,title in tqdm(enumerate(shuffle_df1['title'])) : #전체 문장\n",
    "    okt_title = converter.pos(title)\n",
    "    token = [tup[0].upper() for tup in okt_title if tup[1] == 'Noun' or tup[1] == 'Alpha']\n",
    "    sentences.append(' '.join(sample(token,len(token))))\n",
    "    \n",
    "for index,title in tqdm(enumerate(shuffle_df2['title'])) : #전체 문장 섞음\n",
    "    okt_title = converter.pos(title)\n",
    "    token = [tup[0].upper() for tup in okt_title if tup[1] == 'Noun' or tup[1] == 'Alpha']\n",
    "    sentences.append(' '.join(sample(token,len(token))))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "simplified-female",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10443"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "generous-brunswick",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_label = sector_label+shuffle1_label+shuffle2_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "respected-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10443"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sector_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "alike-opening",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tfds.deprecated.text.SubwordTextEncoder.build_from_corpus(\n",
    "    sentences + sector_label, target_vocab_size=2**13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "square-philippines",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시작 토큰 번호 : [2792]\n",
      "종료 토큰 번호 : [2793]\n",
      "단어 집합의 크기 : 2794\n"
     ]
    }
   ],
   "source": [
    "START_TOKEN, END_TOKEN = [tokenizer.vocab_size], [tokenizer.vocab_size + 1]\n",
    "VOCAB_SIZE = tokenizer.vocab_size + 2\n",
    "\n",
    "print('시작 토큰 번호 :',START_TOKEN)\n",
    "print('종료 토큰 번호 :',END_TOKEN)\n",
    "print('단어 집합의 크기 :',VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "historical-booth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이를 40으로 정의\n",
    "MAX_LENGTH = 20\n",
    "\n",
    "# 토큰화 / 정수 인코딩 / 시작 토큰과 종료 토큰 추가 / 패딩\n",
    "def tokenize_and_filter(inputs, outputs):\n",
    "    tokenized_inputs, tokenized_outputs = [], []\n",
    "\n",
    "    for (sentence1, sentence2) in zip(inputs, outputs):\n",
    "        # encode(토큰화 + 정수 인코딩), 시작 토큰과 종료 토큰 추가\n",
    "        sentence1 = START_TOKEN + tokenizer.encode(sentence1) + END_TOKEN\n",
    "        sentence2 = START_TOKEN + tokenizer.encode(sentence2) + END_TOKEN\n",
    "\n",
    "        tokenized_inputs.append(sentence1)\n",
    "        tokenized_outputs.append(sentence2)\n",
    "\n",
    "        # 패딩\n",
    "    tokenized_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_inputs, maxlen=MAX_LENGTH, padding='post')\n",
    "    tokenized_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        tokenized_outputs, maxlen=MAX_LENGTH, padding='post')\n",
    "\n",
    "    return tokenized_inputs, tokenized_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "characteristic-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions, answers = tokenize_and_filter(sentences, sector_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "direct-zealand",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문 데이터의 크기(shape) : (10443, 20)\n",
      "답변 데이터의 크기(shape) : (10443, 20)\n"
     ]
    }
   ],
   "source": [
    "print('질문 데이터의 크기(shape) :', questions.shape)\n",
    "print('답변 데이터의 크기(shape) :', answers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "micro-aging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2792  111   79   50    4 2793    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "[2792    3 2581    1 2793    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "print(questions[0])\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "arbitrary-monitoring",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 20000\n",
    "\n",
    "# 디코더의 실제값 시퀀스에서는 시작 토큰을 제거해야 한다.\n",
    "dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {\n",
    "        'inputs': questions,\n",
    "        'dec_inputs': answers[:, :-1] # 디코더의 입력. 마지막 패딩 토큰이 제거된다.\n",
    "    },\n",
    "    {\n",
    "        'outputs': answers[:, 1:]  # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다.\n",
    "    },\n",
    "))\n",
    "\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "residential-likelihood",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2792    3 2581    1 2793    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n",
      "[[2792    3 2581    1 2793    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n",
      "[[   3 2581    1 2793    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(answers[0]) # 기존 샘플\n",
    "print(answers[:1][:, :-1]) # 마지막 패딩 토큰 제거하면서 길이가 39가 된다.\n",
    "print(answers[:1][:, 1:]) # 맨 처음 토큰이 제거된다. 다시 말해 시작 토큰이 제거된다. 길이는 역시 39가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "failing-ranch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2794, 256)\n",
      "(1, 2794, 256)\n",
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "inputs (InputLayer)             [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dec_inputs (InputLayer)         [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Functional)            (None, None, 256)    1769472     inputs[0][0]                     \n",
      "                                                                 enc_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "look_ahead_mask (Lambda)        (None, 1, None, None 0           dec_inputs[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dec_padding_mask (Lambda)       (None, 1, 1, None)   0           inputs[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Functional)            (None, None, 256)    2296832     dec_inputs[0][0]                 \n",
      "                                                                 encoder[0][0]                    \n",
      "                                                                 look_ahead_mask[0][0]            \n",
      "                                                                 dec_padding_mask[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "outputs (Dense)                 (None, None, 2794)   718058      decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 4,784,362\n",
      "Trainable params: 4,784,362\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from model.transformer import transformer,CustomSchedule,loss_function\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "# Hyper-parameters\n",
    "D_MODEL = 256\n",
    "NUM_LAYERS = 2\n",
    "NUM_HEADS = 8\n",
    "DFF = 512\n",
    "DROPOUT = 0.1\n",
    "\n",
    "model = transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    dff=DFF,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "professional-lightning",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = CustomSchedule(D_MODEL)\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(\n",
    "    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n",
    "\n",
    "# def accuracy(y_true, y_pred):\n",
    "#     # 레이블의 크기는 (batch_size, MAX_LENGTH - 1)\n",
    "#     y_true = tf.reshape(y_true, shape=(-1, MAX_LENGTH - 1))\n",
    "#     return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss_function,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bigger-discretion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "164/164 [==============================] - 24s 124ms/step - loss: 1.3103 - accuracy: 0.0231\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 21s 126ms/step - loss: 0.6234 - accuracy: 0.1035\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 21s 126ms/step - loss: 0.1844 - accuracy: 0.1510\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 20s 125ms/step - loss: 0.0585 - accuracy: 0.1743\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0240 - accuracy: 0.1790\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0122 - accuracy: 0.1827\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 21s 125ms/step - loss: 0.0074 - accuracy: 0.1822\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0056 - accuracy: 0.1831\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 21s 127ms/step - loss: 0.0047 - accuracy: 0.1835\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 21s 125ms/step - loss: 0.0042 - accuracy: 0.1836\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 21s 127ms/step - loss: 0.0043 - accuracy: 0.1844\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0035 - accuracy: 0.1842\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0031 - accuracy: 0.1831\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 21s 126ms/step - loss: 0.0039 - accuracy: 0.1839\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 21s 128ms/step - loss: 0.0028 - accuracy: 0.1848\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0034 - accuracy: 0.1855\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 20s 123ms/step - loss: 0.0033 - accuracy: 0.1847\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 21s 128ms/step - loss: 0.0050 - accuracy: 0.1846\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 21s 125ms/step - loss: 0.0030 - accuracy: 0.1841\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 21s 128ms/step - loss: 0.0042 - accuracy: 0.1844\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 22s 131ms/step - loss: 0.0037 - accuracy: 0.1855\n",
      "Epoch 22/50\n",
      "164/164 [==============================] - 21s 125ms/step - loss: 0.0034 - accuracy: 0.1845\n",
      "Epoch 23/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0035 - accuracy: 0.1830\n",
      "Epoch 24/50\n",
      "164/164 [==============================] - 20s 125ms/step - loss: 0.0031 - accuracy: 0.1848\n",
      "Epoch 25/50\n",
      "164/164 [==============================] - 21s 125ms/step - loss: 0.0043 - accuracy: 0.1833\n",
      "Epoch 26/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0031 - accuracy: 0.1845\n",
      "Epoch 27/50\n",
      "164/164 [==============================] - 21s 127ms/step - loss: 0.0025 - accuracy: 0.1860\n",
      "Epoch 28/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0035 - accuracy: 0.1848\n",
      "Epoch 29/50\n",
      "164/164 [==============================] - 21s 127ms/step - loss: 0.0030 - accuracy: 0.1847\n",
      "Epoch 30/50\n",
      "164/164 [==============================] - 21s 125ms/step - loss: 0.0028 - accuracy: 0.1854\n",
      "Epoch 31/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0022 - accuracy: 0.1850\n",
      "Epoch 32/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0033 - accuracy: 0.1845\n",
      "Epoch 33/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0024 - accuracy: 0.1846\n",
      "Epoch 34/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0023 - accuracy: 0.1853\n",
      "Epoch 35/50\n",
      "164/164 [==============================] - 20s 123ms/step - loss: 0.0023 - accuracy: 0.1839\n",
      "Epoch 36/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0025 - accuracy: 0.1840\n",
      "Epoch 37/50\n",
      "164/164 [==============================] - 20s 125ms/step - loss: 0.0020 - accuracy: 0.1854\n",
      "Epoch 38/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0019 - accuracy: 0.1849\n",
      "Epoch 39/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0021 - accuracy: 0.1848\n",
      "Epoch 40/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0021 - accuracy: 0.1839\n",
      "Epoch 41/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0013 - accuracy: 0.1858\n",
      "Epoch 42/50\n",
      "164/164 [==============================] - 20s 125ms/step - loss: 0.0021 - accuracy: 0.1848\n",
      "Epoch 43/50\n",
      "164/164 [==============================] - 21s 125ms/step - loss: 0.0012 - accuracy: 0.1850\n",
      "Epoch 44/50\n",
      "164/164 [==============================] - 20s 124ms/step - loss: 0.0015 - accuracy: 0.1857\n",
      "Epoch 45/50\n",
      "164/164 [==============================] - 20s 123ms/step - loss: 0.0011 - accuracy: 0.1852\n",
      "Epoch 46/50\n",
      "164/164 [==============================] - 20s 123ms/step - loss: 0.0014 - accuracy: 0.1857\n",
      "Epoch 47/50\n",
      "164/164 [==============================] - 20s 123ms/step - loss: 0.0015 - accuracy: 0.1846\n",
      "Epoch 48/50\n",
      "164/164 [==============================] - 20s 123ms/step - loss: 0.0019 - accuracy: 0.1848\n",
      "Epoch 49/50\n",
      "164/164 [==============================] - 20s 123ms/step - loss: 0.0017 - accuracy: 0.1848\n",
      "Epoch 50/50\n",
      "164/164 [==============================] - 20s 123ms/step - loss: 0.0015 - accuracy: 0.1847\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc24ab6b190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "model.fit(dataset, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "tamil-england",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(sentence):\n",
    "    sentence = tf.expand_dims(\n",
    "      START_TOKEN + tokenizer.encode(sentence) + END_TOKEN, axis=0)\n",
    "\n",
    "    output = tf.expand_dims(START_TOKEN, 0)\n",
    "\n",
    "    # 디코더의 예측 시작\n",
    "    for i in range(MAX_LENGTH):\n",
    "        predictions = model(inputs=[sentence, output], training=False)\n",
    "\n",
    "        # 현재(마지막) 시점의 예측 단어를 받아온다.\n",
    "        predictions = predictions[:, -1:, :]\n",
    "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
    "\n",
    "        # 만약 마지막 시점의 예측 단어가 종료 토큰이라면 예측을 중단\n",
    "        if tf.equal(predicted_id, END_TOKEN[0]):\n",
    "              break\n",
    "\n",
    "        # 마지막 시점의 예측 단어를 출력에 연결한다.\n",
    "        # 이는 for문을 통해서 디코더의 입력으로 사용될 예정이다.\n",
    "        output = tf.concat([output, predicted_id], axis=-1)\n",
    "\n",
    "    return tf.squeeze(output, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "classical-vector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(sentence):\n",
    "    sentence = sentence.upper()\n",
    "    okt_title = converter.pos(sentence)\n",
    "    sentence = ' '.join([tup[0].upper() for tup in okt_title if tup[1] == 'Noun' or tup[1] == 'Alpha'])\n",
    "    prediction = evaluate(sentence)\n",
    "\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "      [i for i in prediction if i < tokenizer.vocab_size])\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Output: {}'.format(predicted_sentence))\n",
    "\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "convenient-charge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 데이터 프로 덕트 매니저\n",
      "Output: Project-manager\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"데이터 프로덕트 매니저\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "southeast-stake",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 클라이언트 개발자 캐 주얼 게임\n",
      "Output: Game\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"클라이언트 개발자 (캐주얼 게임)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "maritime-corrections",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: TECH LEAD MANAGER\n",
      "Output: CTO\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"Tech Lead Manager\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "august-grammar",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 머신 러닝 데이터 분석\n",
      "Output: Machine-learning\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"머신러닝/데이터 분석가\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "focused-dutch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 풀 스택 엔지니어 이상\n",
      "Output: WEB/Full-stack\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"풀스택 엔지니어(2년 이상)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "hidden-caribbean",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: C 개발자\n",
      "Output: C#/C++/C\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"C++ 개발자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "hollywood-being",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: EXCHANGE ADMIN CONSOLE DEVELOPER\n",
      "Output: C#/C++/C\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"Exchange Admin Console Developer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "attended-courtesy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: UX 디자인\n",
      "Output: Web-publisher\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"UX 디자인\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "unauthorized-residence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 커머스 앱 및 시스템 앱 위 REACT NATIVE 개발자\n",
      "Output: Mobile\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"커머스 앱 및 시스템 앱을 위한 React Native 개발자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "satellite-entrance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: UNITY 를 활용 플랫폼 개발자\n",
      "Output: Unity/AR/VR/3D\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"unity를 활용한 플랫폼 개발자\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "sustainable-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: BACK\n",
      "Output: Back-end\n"
     ]
    }
   ],
   "source": [
    "output = predict(\"back\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "convenient-labor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 서버 개발자 FRONTEND ENGINEER\n",
      "Output: WEB/Full-stack\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'WEB/Full-stack'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"서버개발자(Frontend Engineer)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fifth-finnish",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3481it [04:34, 12.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct : 3436, wrong : 45\n",
      "real acc : 0.9870726802642918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "wrong = 0\n",
    "\n",
    "for index,title in tqdm(enumerate(total_df['title'])) : \n",
    "    output = predict(title)\n",
    "    if output == sector_label[index] :\n",
    "        correct += 1\n",
    "    else :\n",
    "        wrong +=1\n",
    "        \n",
    "print(f'correct : {correct}, wrong : {wrong}')\n",
    "print(f'real acc : {correct/3481}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "extraordinary-glucose",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# saving\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "paperback-words",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Layer PositionalEncoding has arguments in `__init__` and therefore must override `get_config`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-e816851f45e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#     json_file.write(model_json)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transformer.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Saved model to disk\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \"\"\"\n\u001b[1;32m   2000\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2001\u001b[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[1;32m   2002\u001b[0m                     signatures, options, save_traces)\n\u001b[1;32m   2003\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    151\u001b[0m           \u001b[0;34m'to the Tensorflow SavedModel format (by setting save_format=\"tf\") '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m--> 153\u001b[0;31m     hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[1;32m    154\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[1;32m    155\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mmodel_metadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaving_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    156\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m   metadata = dict(\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/saving/saving_utils.py\u001b[0m in \u001b[0;36mmodel_metadata\u001b[0;34m(model, include_optimizer, require_config)\u001b[0m\n\u001b[1;32m    153\u001b[0m   \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'class_name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mmodel_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'config'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrequire_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m     \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    248\u001b[0m         return serialize_keras_class_and_config(\n\u001b[1;32m    249\u001b[0m             name, {_LAYER_UNDEFINED_CONFIG_KEY: True})\n\u001b[0;32m--> 250\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 650\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_network_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/functional.py\u001b[0m in \u001b[0;36mget_network_config\u001b[0;34m(network, serialize_layer_fn)\u001b[0m\n\u001b[1;32m   1347\u001b[0m         \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1349\u001b[0;31m     \u001b[0mlayer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mserialize_layer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1350\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1351\u001b[0m     \u001b[0mlayer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inbound_nodes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_inbound_nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    248\u001b[0m         return serialize_keras_class_and_config(\n\u001b[1;32m    249\u001b[0m             name, {_LAYER_UNDEFINED_CONFIG_KEY: True})\n\u001b[0;32m--> 250\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m     \u001b[0mserialization_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mserialize_keras_object\u001b[0;34m(instance)\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_registered_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m       \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_SKIP_FAILED_SERIALIZATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mget_config\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m     \u001b[0;31m# or that `get_config` has been overridden:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextra_args\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_is_default'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m       raise NotImplementedError('Layer %s has arguments in `__init__` and '\n\u001b[0m\u001b[1;32m    700\u001b[0m                                 \u001b[0;34m'therefore must override `get_config`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                                 self.__class__.__name__)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Layer PositionalEncoding has arguments in `__init__` and therefore must override `get_config`."
     ]
    }
   ],
   "source": [
    "# model_json = model.to_json()\n",
    "# with open(\"transformer.json\", \"w\") as json_file : \n",
    "#     json_file.write(model_json)\n",
    "    \n",
    "model.save(\"transformer.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adverse-fifth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading\n",
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "polish-gather",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model found in config file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-88ca61aaffff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'transformer.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mloaded_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    204\u001b[0m       if (h5py is not None and\n\u001b[1;32m    205\u001b[0m           (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 206\u001b[0;31m         return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0m\u001b[1;32m    207\u001b[0m                                                 compile)\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/coding/WhyDoThat/analysis/anal-env/lib/python3.8/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     model = model_config_lib.model_from_config(model_config,\n",
      "\u001b[0;31mValueError\u001b[0m: No model found in config file."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model('transformer.h5')\n",
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-format",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-analenv",
   "language": "python",
   "name": "anal-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
